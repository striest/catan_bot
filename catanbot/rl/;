from torch import nn
import matplotlib.pyplot as plt
import copy

from catanbot.core.board import Board
from catanbot.agents.independent_actions_agents import IndependentActionsHeuristicAgent, IndependentActionsAgent
from catanbot.board_placement.agents.base import InitialPlacementAgent
from catanbot.board_placement.agents.mlp_agent import MLPPlacementAgent
from catanbot.core.independent_action_simulator import IndependentActionsCatanSimulator
from catanbot.board_placement.initial_placement_simulator import InitialPlacementSimulator

from catanbot.rl.networks.mlp import MLP
from catanbot.rl.networks.valuemlp import VMLP
from catanbot.rl.collectors.initial_placement_collector import InitialPlacementCollector
from catanbot.rl.collectors.base import ParallelizeCollector
from catanbot.rl.replaybuffers.simple_replay_buffer import SimpleReplayBuffer

from catanbot.rl.algos.ma_a2c import MultiagentA2C

from catanbot.rl.experiments.experiment import Experiment

b = Board() 
b.reset()
#    agents = [IndependentActionsAgent(b), IndependentActionsAgent(b), IndependentActionsHeuristicAgent(b), IndependentActionsAgent(b)]
agents = [IndependentActionsHeuristicAgent(b), IndependentActionsHeuristicAgent(b), IndependentActionsHeuristicAgent(b), IndependentActionsHeuristicAgent(b)]
#    agents = [HeuristicAgent(b), HeuristicAgent(b), HeuristicAgent(b), HeuristicAgent(b)]
s = IndependentActionsCatanSimulator(board=b, players = agents, max_vp=10)

insize = s.observation_space['total']
outsize = 54*3
hiddens = [512, 512, 256]
shared_mlp = MLP(insize, outsize, hiddens, gpu=False)

#placement_agents = [MLPPlacementAgent(b, MLP(insize, outsize, hiddens)), MLPPlacementAgent(b, MLP(insize, outsize, hiddens)), MLPPlacementAgent(b, MLP(insize, outsize, hiddens)), MLPPlacementAgent(b, MLP(insize, outsize, hiddens))]
placement_agents = [MLPPlacementAgent(b, MLP(insize, outsize, hiddens)), InitialPlacementAgent(b), InitialPlacementAgent(b), InitialPlacementAgent(b)]
#placement_agents = [MLPPlacementAgent(b, shared_mlp), MLPPlacementAgent(b, shared_mlp), MLPPlacementAgent(b, shared_mlp), MLPPlacementAgent(b, shared_mlp)]
placement_simulator = InitialPlacementSimulator(s, placement_agents)

vf = VMLP(placement_simulator, hiddens = hiddens, scale=10., gpu=False)

collector = InitialPlacementCollector(placement_simulator, reset_board=True, reward_scale=10.)
#collector = ParallelizeCollector(collector, nthreads=16)
#buf = SimpleReplayBuffer(placement_simulator, capacity = int(1e6))

algo = MultiagentA2C(placement_simulator, placement_agents, vf, collector, rollouts_per_epoch = 200)

experiment = Experiment(algo, '../../../experiments/catan_initial_placement_a2c', save_every=5, save_logs_every=5)
import torch
with torch.autograd.set_detect_anomaly(True):
    experiment.run()

